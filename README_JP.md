<p align="center">
<img src="img/logo_ver2.png" width="300">
</p>

<h1>
<p align="center">
MaAI
</p>
</h1>
<p align="center"><b>ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ </b>ã‹ã¤<b>è»½é‡</b>ãªä¼šè©±AIå‘ã‘<b>éè¨€èªçš„ãµã‚‹ã¾ã„ç”Ÿæˆ</b>ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢</p>
<p align="center">ï¼ˆVoice Activity Projectionã®ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å®Ÿè£…ï¼‰</p>
<p align="center">
ğŸ“„ README: <a href="README.md">English </a> | <a href="README_JP.md">Japanese (æ—¥æœ¬èª) </a>
</p>

<b>MaAI</b>ã¯ï¼ˆï¼‘ï¼‰<b>ã‚¿ãƒ¼ãƒ³ãƒ†ã‚¤ã‚­ãƒ³ã‚°</b>ã€ï¼ˆï¼’ï¼‰<b>ç›¸æ§Œ</b>ã€ï¼ˆï¼“ï¼‰<b>é ·ã</b>ã‚’ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã‹ã¤é€£ç¶šçš„ã«äºˆæ¸¬ã™ã‚‹ã€æœ€å…ˆç«¯ã‹ã¤è»½é‡ãªã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢ã§ã™ã€‚
è‹±èªãƒ»ä¸­å›½èªãƒ»æ—¥æœ¬èªã«å¯¾å¿œã—ã¦ãŠã‚Šã€ä»Šå¾Œã‚‚å¯¾å¿œè¨€èªã‚„ãµã‚‹ã¾ã„ã®ç¨®é¡ã‚’æ‹¡å¤§äºˆå®šã§ã™ã€‚
ä¼šè©±AIï¼ˆå¯¾è©±ã‚·ã‚¹ãƒ†ãƒ ã‚„ãƒ­ãƒœãƒƒãƒˆç­‰ï¼‰å‘ã‘ã«è¨­è¨ˆã•ã‚Œã¦ãŠã‚Šã€2ãƒãƒ£ãƒ³ãƒãƒ«ï¼ˆãƒ¦ãƒ¼ã‚¶ãƒ»ã‚·ã‚¹ãƒ†ãƒ ï¼‰ã¾ãŸã¯1ãƒãƒ£ãƒ³ãƒãƒ«ï¼ˆãƒ¦ãƒ¼ã‚¶ã®ã¿ï¼‰ã®éŸ³å£°å…¥åŠ›ã«å¯¾å¿œã—ã¾ã™ã€‚ğŸ™ï¸
è»½é‡è¨­è¨ˆã®ãŸã‚ã€CPUã®ã¿ã§ã‚‚é«˜é€Ÿã«å‹•ä½œã—ã¾ã™ã€‚âš¡

ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®åç§°ã®<b>MaAI</b>ã¯ã€æ—¥æœ¬èªã®<b>é–“ï¼ˆã¾ï¼‰</b>ã‚„<b>é–“åˆã„</b>ã«ç”±æ¥ã—ã€ä¼šè©±ã«ãŠã‘ã‚‹ã‚¿ã‚¤ãƒŸãƒ³ã‚°ã‚„é–“åˆã„ã®èª¿æ•´ã‚’AIã§å®Ÿç¾ã™ã‚‹ã“ã¨ã‚’ç›®æŒ‡ã—ã¦ã„ã¾ã™ã€‚

ç¾åœ¨ã‚µãƒãƒ¼ãƒˆã—ã¦ã„ã‚‹ãƒ¢ãƒ‡ãƒ«ã¯ä¸»ã«Voice Activity Projectionï¼ˆVAPï¼‰ãŠã‚ˆã³ãã®æ‹¡å¼µã§ã™ã€‚
VAPãƒ¢ãƒ‡ãƒ«ã®è©³ç´°ã¯ä»¥ä¸‹ã®ãƒªãƒã‚¸ãƒˆãƒªã‚’å‚ç…§ã—ã¦ãã ã•ã„ï¼š
https://github.com/ErikEkstedt/VoiceActivityProjection

<b>MaAIã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢ã‚’ä½¿ç”¨ã—ãŸã‚·ã‚¹ãƒ†ãƒ é–‹ç™ºãƒ»å…±åŒç ”ç©¶</b>ãªã©ã¯äº¬éƒ½å¤§å­¦ã®[äº•ä¸Šæ˜‚æ²»](https://inokoj.github.io/)ã¾ã§ã”ç›¸è«‡ã„ãŸã ã‘ã¾ã™ã¨å¹¸ã„ã§ã™ã€‚

<br>

__ãƒ‡ãƒ¢å‹•ç”»ï¼ˆYouTubeï¼‰__ (https://www.youtube.com/watch?v=-uwB6yl2WtI)

[![Demo video](http://img.youtube.com/vi/-uwB6yl2WtI/0.jpg)](https://www.youtube.com/watch?v=-uwB6yl2WtI)

<br>

## ğŸ†• æ–°ç€æƒ…å ±

- MaAIãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãŠã‚ˆã³ãƒªãƒã‚¸ãƒˆãƒªã‚’å…¬é–‹ã—ã¾ã—ãŸï¼ğŸš€ï¼ˆ2025å¹´7æœˆ24æ—¥ï¼‰

<br>

## ğŸš€ ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«

MaAIã¯pipã§ç°¡å˜ã«ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã§ãã¾ã™ï¼š

```bash
pip install maai
```

> ğŸ’¡ **æ³¨æ„:** ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§ã¯PyTorchã®CPUç‰ˆãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¾ã™ã€‚GPUã§åˆ©ç”¨ã—ãŸã„å ´åˆã¯ã€äº‹å‰ã«CUDAç’°å¢ƒã«åˆã£ãŸPyTorchã®GPUç‰ˆã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¦ãã ã•ã„ã€‚

ä»¥ä¸‹ã®ã‚ˆã†ã«å®Ÿè¡Œã§ãã¾ã™ã€‚ğŸƒâ€â™‚ï¸
ã‚¿ã‚¹ã‚¯ï¼ˆmodeï¼‰ã«å¿œã˜ãŸãƒ¢ãƒ‡ãƒ«ã‚„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¯è‡ªå‹•ã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¾ã™ã€‚
ä¸‹è¨˜ã¯ï¼‘ãƒãƒ£ãƒãƒ«ç›®ã¯ãƒã‚¤ã‚¯å…¥åŠ›ï¼ˆãƒ¦ãƒ¼ã‚¶ï¼‰ã€ï¼’ãƒãƒ£ãƒãƒ«ç›®ã¯ç„¡éŸ³ï¼ˆã‚·ã‚¹ãƒ†ãƒ ï¼‰ã‚’ã‚¿ãƒ¼ãƒ³ãƒ†ã‚¤ã‚­ãƒ³ã‚°ãƒ¢ãƒ‡ãƒ«ï¼ˆVAPï¼‰ã«å…¥åŠ›ã™ã‚‹ä¾‹ã§ã™ã€‚

```python
from maai import Maai, MaaiInput, MaaiOutput

mic = MaaiInput.Mic()
zero = MaaiInput.Zero() 

maai = Maai(mode="vap", language="jp", frame_rate=10, context_len_sec=5, audio_ch1=mic, audio_ch2=zero, device="cpu")
maai_output_bar = MaaiOutput.ConsoleBar(bar_type="balance")

maai.start_process()
while True:
    result = maai.get_result()
    maai_output_bar.update(result)
```

<br>

## ğŸ§© ãƒ¢ãƒ‡ãƒ«

å¯¾å¿œãƒ¢ãƒ‡ãƒ«ï¼ˆãµã‚‹ã¾ã„ãƒ»è¨€èªãƒ»è¨­å®šãªã©ï¼‰ã¯ä»Šå¾Œã‚‚è¿½åŠ äºˆå®šã§ã™ã€‚
ç¾åœ¨åˆ©ç”¨å¯èƒ½ãªãƒ¢ãƒ‡ãƒ«ã¯[HuggingFaceãƒªãƒã‚¸ãƒˆãƒª](https://huggingface.co/maai-kyoto)ã‚’ã”è¦§ãã ã•ã„ã€‚

### ã‚¿ãƒ¼ãƒ³ãƒ†ã‚¤ã‚­ãƒ³ã‚°

ã‚¿ãƒ¼ãƒ³ãƒ†ã‚¤ã‚­ãƒ³ã‚°ãƒ¢ãƒ‡ãƒ«ã¯VAPã‚’ç”¨ã„ã€æ¬¡ã®ç¬é–“ã«ã©ã¡ã‚‰ãŒç™ºè©±ã™ã‚‹ã‹ã‚’äºˆæ¸¬ã—ã¾ã™ã€‚

- [VAPãƒ¢ãƒ‡ãƒ«](readme/vap_JP.md)
- [ãƒã‚¤ã‚ºãƒ­ãƒã‚¹ãƒˆVAPãƒ¢ãƒ‡ãƒ«ï¼ˆ<b>æ¨å¥¨</b>ï¼‰](readme/vap_mc_JP.md)
- [1ãƒãƒ£ãƒ³ãƒãƒ«VAPãƒ¢ãƒ‡ãƒ«]  (æº–å‚™ä¸­)

### ç›¸æ§Œ

ç›¸æ§Œã¯ã€Œã†ã‚“ã€ã€Œã¯ã„ã€ãªã©ã®çŸ­ã„èãæ‰‹åå¿œã§ã€ã‚¿ãƒ¼ãƒ³ãƒ†ã‚¤ã‚­ãƒ³ã‚°ã¨ã‚‚é–¢é€£ã—ã¾ã™ã€‚

- [VAPãƒ™ãƒ¼ã‚¹ã®ç›¸æ§Œäºˆæ¸¬ãƒ¢ãƒ‡ãƒ« - 2ç¨®é¡ã®ã‚¿ã‚¤ãƒŸãƒ³ã‚°](readme/vap_bc_2type_JP.md)
- [VAPãƒ™ãƒ¼ã‚¹ã®ç›¸æ§Œäºˆæ¸¬ãƒ¢ãƒ‡ãƒ« - ã‚¿ã‚¤ãƒŸãƒ³ã‚°ã®ã¿]  (æº–å‚™ä¸­)

### é ·ã

é ·ãã¯é ­ã®ä¸Šä¸‹é‹å‹•ã§ã€ç›¸æ§Œã¨é–¢é€£ã—ã¾ã™ã€‚ç™ºå£°ã‚’ä¼´ã‚ãšéè¨€èªçš„ã«èãæ‰‹åå¿œã‚’ç¤ºã™ã“ã¨ãŒã§ãã¾ã™ã€‚

- [VAPãƒ™ãƒ¼ã‚¹ã®é ·ãäºˆæ¸¬ãƒ¢ãƒ‡ãƒ«](readme/vap_nod_JP.md)

<br>

## ğŸšï¸ å…¥å‡ºåŠ›

MaAIãƒ¢ãƒ‡ãƒ«ã¸ã®å…¥åŠ›ã¯ã€`Maai`ã‚¯ãƒ©ã‚¹ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã®`process`ãƒ¡ã‚½ãƒƒãƒ‰ã‚’ç›´æ¥å‘¼ã³å‡ºã›ã¾ã™ã€‚
`MaaiInput`ã‚¯ãƒ©ã‚¹ã«ã‚ˆã‚Šã€WAVãƒ•ã‚¡ã‚¤ãƒ«ãƒ»ãƒã‚¤ã‚¯ãƒ»TCPé€šä¿¡ãªã©æŸ”è»ŸãªéŸ³å£°å…¥åŠ›ãŒå¯èƒ½ã§ã™ã€‚

- WAVãƒ•ã‚¡ã‚¤ãƒ«å…¥åŠ›: `Wav`ã‚¯ãƒ©ã‚¹ ğŸ“
- ãƒã‚¤ã‚¯å…¥åŠ›: `Mic`ã‚¯ãƒ©ã‚¹ ğŸ™ï¸
- TCPé€šä¿¡: `TCPReceiver` / `TCPTransmitter`ã‚¯ãƒ©ã‚¹ ğŸŒ

ã“ã‚Œã‚‰ã®ã‚¯ãƒ©ã‚¹ã‚’ä½¿ã†ã“ã¨ã§ã€ç”¨é€”ã«å¿œã˜ãŸéŸ³å£°å…¥åŠ›æ–¹æ³•ã‚’ç°¡å˜ã«åˆ‡ã‚Šæ›¿ãˆã‚‰ã‚Œã¾ã™ã€‚

å‡¦ç†çµæœã¯ã€`Maai`ã‚¯ãƒ©ã‚¹ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã®`get_result`ãƒ¡ã‚½ãƒƒãƒ‰ã§å–å¾—ã§ãã¾ã™ã€‚
ã¾ãŸã€`MaaiOutput`ã‚¯ãƒ©ã‚¹ã‚’ä½¿ã†ã“ã¨ã§ã€ã•ã¾ã–ã¾ãªå¯è¦–åŒ–ã‚„TCPé€šä¿¡ã«ã‚ˆã‚‹å‡ºåŠ›ã‚‚å¯èƒ½ã§ã™ã€‚

- ã‚³ãƒ³ã‚½ãƒ¼ãƒ«å‹•çš„å‡ºåŠ›: `ConsoleBar`ã‚¯ãƒ©ã‚¹ ğŸ“Š
- TCPé€šä¿¡: `TCPReceiver` / `TCPTransmitter`ã‚¯ãƒ©ã‚¹ ğŸŒ

è©³ç´°ã¯ä»¥ä¸‹ã®READMEã‚‚ã”å‚ç…§ãã ã•ã„ï¼š
- [å…¥åŠ›ã«ã¤ã„ã¦](readme/input_JP.md)
- [å‡ºåŠ›ã«ã¤ã„ã¦](readme/output_JP.md)

<br>

## ğŸ’¡ å®Ÿè£…ä¾‹

`test_scripts`ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«MaAIãƒ¢ãƒ‡ãƒ«ã®å®Ÿè£…ä¾‹ãŒã‚ã‚Šã¾ã™ã€‚

- ã‚¿ãƒ¼ãƒ³ãƒ†ã‚¤ã‚­ãƒ³ã‚°ï¼ˆVAPï¼‰
    - [2wavãƒ•ã‚¡ã‚¤ãƒ«](test_scripts/test_vap_module_2wav.py) ğŸ§
    - [2ãƒã‚¤ã‚¯å…¥åŠ›](test_scripts/test_vap_module_2mic.py) ğŸ¤
    - [2ãƒã‚¤ã‚¯å…¥åŠ›(TCPçµŒç”±)](test_scripts/test_vap_module_2tcp.py) ğŸŒ
    - [1wavãƒ•ã‚¡ã‚¤ãƒ« ã¨ 1ãƒã‚¤ã‚¯å…¥åŠ›](test_scripts/test_vap_module_wav_mic.py) ğŸ§ğŸ¤

- ç›¸æ§Œ
    - [1ãƒã‚¤ã‚¯å…¥åŠ› ã¨ ç„¡éŸ³](test_scripts/test_vap_bc_2type_mic.py) ğŸ¤

- é ·ã
    - [1wavãƒ•ã‚¡ã‚¤ãƒ« ã¨ 1ãƒã‚¤ã‚¯å…¥åŠ›](test_scripts/test_vap_nod_module_wav_mic.py) ğŸ§ğŸ¤

<br>

## ğŸ“š è«–æ–‡ãƒ»å‚è€ƒæ–‡çŒ®

æœ¬ãƒªãƒã‚¸ãƒˆãƒªã‚’åˆ©ç”¨ã—ãŸæˆæœã‚’ç™ºè¡¨ã™ã‚‹éš›ã¯ã€ä»¥ä¸‹ã®è«–æ–‡ã‚’å¼•ç”¨ã—ã¦ãã ã•ã„ã€‚ğŸ™

Koji Inoue, Bing'er Jiang, Erik Ekstedt, Tatsuya Kawahara, Gabriel Skantze<br>
__Real-time and Continuous Turn-taking Prediction Using Voice Activity Projection__<br>
International Workshop on Spoken Dialogue Systems Technology (IWSDS), 2024<br>
https://arxiv.org/abs/2401.04868<br>

```
@inproceedings{inoue2024iwsds,
    author = {Koji Inoue and Bing'er Jiang and Erik Ekstedt and Tatsuya Kawahara and Gabriel Skantze},
    title = {Real-time and Continuous Turn-taking Prediction Using Voice Activity Projection},
    booktitle = {International Workshop on Spoken Dialogue Systems Technology (IWSDS)},
    year = {2024},
    url = {https://arxiv.org/abs/2401.04868},
}
```

ãƒˆãƒªãƒªãƒ³ã‚¬ãƒ«VAPãƒ¢ãƒ‡ãƒ«ã‚’åˆ©ç”¨ã™ã‚‹å ´åˆã¯ã€ä»¥ä¸‹ã‚‚å¼•ç”¨ã—ã¦ãã ã•ã„ã€‚

Koji Inoue, Bing'er Jiang, Erik Ekstedt, Tatsuya Kawahara, Gabriel Skantze<br>
__Multilingual Turn-taking Prediction Using Voice Activity Projection__<br>
Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING), pages 11873-11883, 2024<br>
https://aclanthology.org/2024.lrec-main.1036/<br>

```
@inproceedings{inoue2024lreccoling,
    author = {Koji Inoue and Bing'er Jiang and Erik Ekstedt and Tatsuya Kawahara and Gabriel Skantze},
    title = {Multilingual Turn-taking Prediction Using Voice Activity Projection},
    booktitle = {Proceedings of the Joint International Conference on Computational Linguistics and Language Resources and Evaluation (LREC-COLING)},
    pages = {11873--11883},
    year = {2024},
    url = {https://aclanthology.org/2024.lrec-main.1036/},
}
```

ãƒã‚¤ã‚ºãƒ­ãƒã‚¹ãƒˆVAPãƒ¢ãƒ‡ãƒ«ã‚’åˆ©ç”¨ã™ã‚‹å ´åˆã¯ã€ä»¥ä¸‹ã‚‚å¼•ç”¨ã—ã¦ãã ã•ã„ã€‚

Koji Inoue, Yuki Okafuji, Jun Baba, Yoshiki Ohira, Katsuya Hyodo, Tatsuya Kawahara<br>
__A Noise-Robust Turn-Taking System for Real-World Dialogue Robots: A Field Experiment__<br>
https://www.arxiv.org/abs/2503.06241<br>

```
@misc{inoue2025noisevap,
    author = {Koji Inoue and Yuki Okafuji and Jun Baba and Yoshiki Ohira and Katsuya Hyodo and Tatsuya Kawahara},
    title = {A Noise-Robust Turn-Taking System for Real-World Dialogue Robots: A Field Experiment},
    year = {2025},
    note = {arXiv:2503.06241},
    url = {https://www.arxiv.org/abs/2503.06241},
}
```

ç›¸æ§ŒVAPãƒ¢ãƒ‡ãƒ«ã‚’åˆ©ç”¨ã™ã‚‹å ´åˆã¯ã€ä»¥ä¸‹ã‚‚å¼•ç”¨ã—ã¦ãã ã•ã„ã€‚

Koji Inoue, Divesh Lala, Gabriel Skantze, Tatsuya Kawaharaa<br>
__Yeah, Un, Oh: Continuous and Real-time Backchannel Prediction with Fine-tuning of Voice Activity Projection__<br>
https://aclanthology.org/2025.naacl-long.367/<br>

```
@inproceedings{inoue2025vapbc,
    author = {Koji Inoue and Divesh Lala and Gabriel Skantze and Tatsuya Kawahara},
    title = {Yeah, Un, Oh: Continuous and Real-time Backchannel Prediction with Fine-tuning of Voice Activity Projection},
    booktitle = {Proceedings of the Conference of the Nations of the Americas Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL)},
    pages = {7171--7181},
    year = {2025},
    url = {https://aclanthology.org/2025.naacl-long.367/},
}
```

<br>

## ğŸ“ ãƒ©ã‚¤ã‚»ãƒ³ã‚¹

æœ¬ãƒªãƒã‚¸ãƒˆãƒªã®ã‚½ãƒ¼ã‚¹ã‚³ãƒ¼ãƒ‰ã¯MITãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã§ã™ã€‚
å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã¯å­¦è¡“ç›®çš„ã®ã¿ã«åˆ©ç”¨å¯èƒ½ã§ã™ã€‚

CPCãƒ¢ãƒ‡ãƒ«ã¯ã‚ªãƒªã‚¸ãƒŠãƒ«CPCãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆç”±æ¥ã§ã™ã€‚
ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã®è©³ç´°ã¯ä»¥ä¸‹ã‚’å‚ç…§ã—ã¦ãã ã•ã„ï¼š
https://github.com/facebookresearch/CPC_audio
